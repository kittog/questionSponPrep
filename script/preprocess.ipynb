{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données\n",
    "Afin d'appliquer les algorithmes d'apprentissage non-supervisé choisis (*k-moyenne* et *clustering hiérarchique*), il nous faut tout d'abord vectoriser nos données. On appliquera notamment le plongement de mots. (TF-IDF) \\\n",
    "\\\n",
    "Ce notebook permet d'obtenir deux dataframes, qui correspondent à nos deux sous-corpus, après l'application de la fonction TF-IDF. On utilise les fichiers `.csv` obtenus comme données d'entrée pour nos algorithmes non-supervisés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première étape : nettoyage des questions\n",
    "On retire tous les *stop-words*, on ne garde que les *stemmers* (pas commparable au lemme : linguistiquement parlant, ce n'est pas très intéressant. On se demande si ce n'est pas le + gros défaut de la méthode pré-traitement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des modules\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des deux sous-corpus\n",
    "data_prep = pd.read_csv(\"../data/corpus_prep.csv\")\n",
    "data_spon = pd.read_csv(\"../data/corpus_spon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/lena/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"french\")\n",
    "stopword = set(stopwords.words('french'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction nettoyage des questions\n",
    "def clean(question):\n",
    "    question = str(question).lower()\n",
    "    question = re.sub('\\[.*?\\]', '', question)\n",
    "    question = re.sub('https?://\\S+|www\\.\\S+', \"\", question)\n",
    "    question = re.sub('<.*?>+', '', question)\n",
    "    question = re.sub('[%s]' % re.escape(string.punctuation), '', question)\n",
    "    question = re.sub('\\n', '', question)\n",
    "    question = re.sub('\\w*\\d\\w*', '', question)\n",
    "    question = [word for word in question.split(' ') if word not in stopword]\n",
    "    question = \" \".join(question)\n",
    "    question = [stemmer.stem(word) for word in question.split(' ')]\n",
    "    question = \" \".join(question)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la fonction à chacun des sous-corpus\n",
    "data_spon[\"question\"] = data_spon[\"question\"].apply(clean)\n",
    "data_spon[\"previous_5_turn\"] = data_spon[\"previous_5_turn\"].apply(clean)\n",
    "data_spon[\"next_5_turn\"] = data_spon[\"next_5_turn\"].apply(clean)\n",
    "\n",
    "data_prep[\"question\"] = data_prep[\"question\"].apply(clean)\n",
    "data_prep[\"previous_5_turn\"] = data_prep[\"previous_5_turn\"].apply(clean)\n",
    "data_prep[\"next_5_turn\"] = data_prep[\"next_5_turn\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering data\n",
    "clustering_data_spon = data_spon[[\"previous_5_turn\", \"question\", \"next_5_turn\"]]\n",
    "clustering_data_prep = data_prep[[\"previous_5_turn\", \"question\", \"next_5_turn\"]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième partie : vectorisation et TF-IDF\n",
    "Vectorisation des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la fonction TF-IDF (plongement de mots)\n",
    "\n",
    "# importation des modules\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus questions uniquement\n",
    "corpus_spon = clustering_data_spon[\"question\"]\n",
    "corpus_prep = clustering_data_prep[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lena/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/lena/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def vectors_tfidf(corpus):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    stemmer = FrenchStemmer()\n",
    "    stopwords_fr = stopwords.words('french')\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, stop_words=stopwords_fr,\n",
    "                                analyzer=\"word\", ngram_range=(1, 3), min_df=5, max_df=0.9)\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    tf_idf = pd.DataFrame(data=x.toarray(),\n",
    "                          columns=vectorizer.get_feature_names_out())\n",
    "    return tf_idf\n",
    "\n",
    "tf_idf_spon = vectors_tfidf(corpus_spon)\n",
    "tf_idf_prep = vectors_tfidf(corpus_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.613833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combien</th>\n",
       "      <td>0.583904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orléan</th>\n",
       "      <td>0.531287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126186</td>\n",
       "      <td>0.252564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a chos</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1         2    3    4    5    6         7    8    9    ...  \\\n",
       "temp     0.613833  0.0  0.000000  0.0  0.0  0.0  0.0  0.646865  0.0  0.0  ...   \n",
       "combien  0.583904  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "orléan   0.531287  1.0  0.905057  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "a        0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "a chos   0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
       "\n",
       "         435  436  437  438  439  440       441       442  443  444  \n",
       "temp     0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  \n",
       "combien  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  \n",
       "orléan   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  \n",
       "a        0.0  0.0  0.0  0.0  0.0  0.0  0.126186  0.252564  0.0  0.0  \n",
       "a chos   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.206196  0.0  0.0  \n",
       "\n",
       "[5 rows x 445 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"{} rows\".format(tf_idf_spon.shape[0]))\n",
    "tf_idf_spon.T.nlargest(5, 0)\n",
    "tf_idf_prep.T.nlargest(5,0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, on sauvegarde les résultats obtenus dans deux fichiers `.csv` distincts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_spon.to_csv(\"data/tf_idf_spon.csv\", encoding=\"utf-8\")\n",
    "tf_idf_spon.to_csv(\"data/tf_idf_prep.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    pourquoi ça \n",
       "1        quest fait comm travail \n",
       "2                quoi ça consist \n",
       "3                    tous détail \n",
       "4    alor cest journ assez longu \n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_spon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    depuis combien temp habitezvous orléan \n",
       "1                           plais à  orléan \n",
       "2                estce compt rest à  orléan \n",
       "3      estce voul bien décrir journ travail \n",
       "4                      questc plaît travail \n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_prep.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
