{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce66ad2",
   "metadata": {},
   "source": [
    "# Prétraitement des textes et verctorisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191e02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f74fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnees\n",
    "data_spon = pd.read_csv(\"../data/corpus_spon.csv\")\n",
    "data_prep = pd.read_csv(\"../data/corpus_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd08ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spon_q = data_spon[\"question\"]\n",
    "data_prep_q = data_prep[\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab14ce0",
   "metadata": {},
   "source": [
    "# Test de l'algorithme clustering hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4158c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets._samples_generator import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8065ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lena/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>624</th>\n",
       "      <th>625</th>\n",
       "      <th>626</th>\n",
       "      <th>627</th>\n",
       "      <th>628</th>\n",
       "      <th>629</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pourquoi</th>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ça</th>\n",
       "      <td>0.600654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a fait</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2    3    4    5    6    7         8    9    \\\n",
       "pourquoi  0.799509  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.554854  0.0   \n",
       "ça        0.600654  0.0  0.660388  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "a         0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "a fait    0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "accord    0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   \n",
       "\n",
       "          ...       624       625  626       627  628  629       630  631  \\\n",
       "pourquoi  ...  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0   \n",
       "ça        ...  0.000000  0.000000  0.0  0.456372  0.0  0.0  0.000000  0.0   \n",
       "a         ...  0.000000  0.329342  0.0  0.000000  0.0  0.0  0.325646  0.0   \n",
       "a fait    ...  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0   \n",
       "accord    ...  0.365736  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0   \n",
       "\n",
       "               632  633  \n",
       "pourquoi  0.000000  0.0  \n",
       "ça        0.000000  0.0  \n",
       "a         0.000000  0.0  \n",
       "a fait    0.000000  0.0  \n",
       "accord    0.208917  0.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# application de la fonction TF-IDF\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "#stemmer = FrenchStemmer()\n",
    "stopwords_fr = stopwords.words('french')\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, stop_words=stopwords_fr, analyzer=\"word\", ngram_range=(1, 3), min_df=5, max_df=0.9)\n",
    "X = vectorizer.fit_transform(data_spon_q)\n",
    "\n",
    "\n",
    "tf_idf = pd.DataFrame(data=X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "# merger avec le dataframe original\n",
    "final_df = tf_idf\n",
    "\n",
    "print(\"{} rows\".format(final_df.shape[0]))\n",
    "final_df.T.nlargest(5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5806699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster import hierarchy as sch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6a8772",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linkage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Construction de l'arbre de clustering\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m linkage_matrix \u001b[39m=\u001b[39m linkage(X\u001b[39m.\u001b[39mtodense(), \u001b[39m'\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m1.6\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmedian(linkage_matrix[:, \u001b[39m2\u001b[39m])\n\u001b[1;32m      4\u001b[0m labels \u001b[39m=\u001b[39m fcluster(linkage_matrix, threshold, criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linkage' is not defined"
     ]
    }
   ],
   "source": [
    "# Construction de l'arbre de clustering\n",
    "linkage_matrix = linkage(X.todense(), 'average')\n",
    "threshold = 1.6 * np.median(linkage_matrix[:, 2])\n",
    "labels = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "\n",
    "# Récupération des échantillons représentatifs de chaque cluster\n",
    "representative_samples = []\n",
    "for i in np.unique(labels):\n",
    "    cluster_indices = np.where(labels == i)[0]\n",
    "    cluster_distances = pairwise_distances(X[cluster_indices], metric='euclidean')\n",
    "    representative_sample_index = cluster_indices[np.argmin(np.mean(cluster_distances, axis=0))]\n",
    "    representative_samples.append(representative_sample_index)\n",
    "\n",
    "# Extraction des caractéristiques représentatives de chaque cluster\n",
    "representative_features = []\n",
    "for i in np.unique(labels):\n",
    "    representative_sample = X[representative_samples[i-1]].toarray().squeeze()\n",
    "    feature_indices = np.argsort(representative_sample)[::-1][:10]  # 选择前10个TF-IDF值最高的特征\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    representative_features.append([feature_names[idx] for idx in feature_indices])\n",
    "\n",
    "# Impression des caractéristiques représentatives de chaque cluster\n",
    "for i, features in enumerate(representative_features):\n",
    "    print(\"Cluster {}: {}\".format(i+1, features))\n",
    "\n",
    "# Visualisation de l'arbre de clustering\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linkage_matrix, truncate_mode='lastp', p=50, leaf_rotation=90., \n",
    "           leaf_font_size=8., labels=labels, no_labels=False)\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
